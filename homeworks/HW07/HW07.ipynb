{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45e34a53",
   "metadata": {},
   "source": [
    "# HW07 — Clustering (KMeans / DBSCAN / Agglomerative)\n",
    "\n",
    "Этот ноутбук соответствует требованиям HW07: EDA, препроцессинг, сравнение алгоритмов, внутренние метрики, PCA-визуализация, устойчивость, сохранение артефактов.\n",
    "\n",
    "**Важно:** помести CSV в папку `homeworks/HW07/data/` и запускай ноутбук из `homeworks/HW07/`, чтобы относительные пути работали.\n",
    "\n",
    "Выбраны датасеты: **01, 02, 03**.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "737da1ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T20:58:16.343031Z",
     "start_time": "2026-01-18T20:58:14.870807Z"
    }
   },
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score, adjusted_rand_score\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "ARTIFACTS_DIR = \"artifacts\"\n",
    "FIG_DIR = os.path.join(ARTIFACTS_DIR, \"figures\")\n",
    "LABELS_DIR = os.path.join(ARTIFACTS_DIR, \"labels\")\n",
    "\n",
    "os.makedirs(FIG_DIR, exist_ok=True)\n",
    "os.makedirs(LABELS_DIR, exist_ok=True)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "496bb4c2",
   "metadata": {},
   "source": [
    "## Вспомогательные функции\n",
    "\n",
    "- загрузка + базовый EDA\n",
    "- вычисление метрик (с учётом шума DBSCAN)\n",
    "- PCA(2D) scatter\n",
    "- подбор параметров для KMeans / DBSCAN / Agglomerative\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "eb8e1821",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T20:58:16.354819Z",
     "start_time": "2026-01-18T20:58:16.347027Z"
    }
   },
   "source": [
    "def load_dataset(path: str):\n",
    "    df = pd.read_csv(path)\n",
    "    sample_id = df[\"sample_id\"].copy()\n",
    "    X = df.drop(columns=[\"sample_id\"]).copy()\n",
    "    return df, sample_id, X\n",
    "\n",
    "\n",
    "def basic_eda(df: pd.DataFrame):\n",
    "    display(df.head())\n",
    "    display(df.info())\n",
    "    display(df.describe(include=\"all\"))\n",
    "    miss = df.isna().mean().sort_values(ascending=False)\n",
    "    display(miss)\n",
    "\n",
    "\n",
    "def compute_metrics(X, labels, *, is_dbscan=False):\n",
    "    labels = np.asarray(labels)\n",
    "\n",
    "    noise_share = None\n",
    "    X_eval, y_eval = X, labels\n",
    "\n",
    "    if is_dbscan:\n",
    "        noise_mask = labels == -1\n",
    "        noise_share = float(noise_mask.mean())\n",
    "        X_eval = X[~noise_mask]\n",
    "        y_eval = labels[~noise_mask]\n",
    "\n",
    "    uniq = np.unique(y_eval)\n",
    "    if len(uniq) < 2:\n",
    "        return {\n",
    "            \"silhouette\": None,\n",
    "            \"davies_bouldin\": None,\n",
    "            \"calinski_harabasz\": None,\n",
    "            \"noise_share\": noise_share,\n",
    "            \"n_clusters\": int(len(uniq)),\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        \"silhouette\": float(silhouette_score(X_eval, y_eval)),\n",
    "        \"davies_bouldin\": float(davies_bouldin_score(X_eval, y_eval)),\n",
    "        \"calinski_harabasz\": float(calinski_harabasz_score(X_eval, y_eval)),\n",
    "        \"noise_share\": noise_share,\n",
    "        \"n_clusters\": int(len(uniq)),\n",
    "    }\n",
    "\n",
    "\n",
    "def pca_scatter(X, labels, title: str, save_path: str):\n",
    "    pca = PCA(n_components=2, random_state=RANDOM_STATE)\n",
    "    Z = pca.fit_transform(X)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(Z[:, 0], Z[:, 1], c=labels, s=12)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"PC1\")\n",
    "    plt.ylabel(\"PC2\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=160)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def pick_best_by_silhouette(results_rows):\n",
    "    filtered = [r for r in results_rows if r.get(\"silhouette\") is not None]\n",
    "    if not filtered:\n",
    "        return None\n",
    "    return max(filtered, key=lambda r: r[\"silhouette\"])\n",
    "\n",
    "\n",
    "def search_kmeans(X_scaled, k_min=2, k_max=15):\n",
    "    rows = []\n",
    "    ks = list(range(k_min, k_max + 1))\n",
    "    for k in ks:\n",
    "        model = KMeans(n_clusters=k, random_state=RANDOM_STATE, n_init=10)\n",
    "        labels = model.fit_predict(X_scaled)\n",
    "        m = compute_metrics(X_scaled, labels)\n",
    "        rows.append({\"algo\": \"kmeans\", \"k\": k, **m})\n",
    "\n",
    "    best = pick_best_by_silhouette(rows)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot([r[\"k\"] for r in rows], [r[\"silhouette\"] if r[\"silhouette\"] is not None else np.nan for r in rows])\n",
    "    plt.title(\"KMeans: silhouette vs k\")\n",
    "    plt.xlabel(\"k\")\n",
    "    plt.ylabel(\"silhouette\")\n",
    "    plt.tight_layout()\n",
    "    return rows, best\n",
    "\n",
    "\n",
    "def search_agglomerative(X_scaled, k_min=2, k_max=15, linkages=(\"ward\", \"average\")):\n",
    "    rows = []\n",
    "    for linkage in linkages:\n",
    "        for k in range(k_min, k_max + 1):\n",
    "            model = AgglomerativeClustering(n_clusters=k, linkage=linkage)\n",
    "            labels = model.fit_predict(X_scaled)\n",
    "            m = compute_metrics(X_scaled, labels)\n",
    "            rows.append({\"algo\": \"agglomerative\", \"k\": k, \"linkage\": linkage, **m})\n",
    "\n",
    "    best = pick_best_by_silhouette(rows)\n",
    "    return rows, best\n",
    "\n",
    "\n",
    "def search_dbscan(X_scaled, eps_grid=None, min_samples_grid=(5, 10)):\n",
    "    if eps_grid is None:\n",
    "        eps_grid = np.linspace(0.2, 2.0, 19)\n",
    "\n",
    "    rows = []\n",
    "    for eps in eps_grid:\n",
    "        for ms in min_samples_grid:\n",
    "            model = DBSCAN(eps=float(eps), min_samples=int(ms))\n",
    "            labels = model.fit_predict(X_scaled)\n",
    "            m = compute_metrics(X_scaled, labels, is_dbscan=True)\n",
    "            rows.append({\"algo\": \"dbscan\", \"eps\": float(eps), \"min_samples\": int(ms), **m})\n",
    "\n",
    "    best = pick_best_by_silhouette(rows)\n",
    "\n",
    "    if best is not None:\n",
    "        ms_best = best[\"min_samples\"]\n",
    "        xs = [r[\"eps\"] for r in rows if r[\"min_samples\"] == ms_best]\n",
    "        ys = [r[\"silhouette\"] if r[\"silhouette\"] is not None else np.nan for r in rows if r[\"min_samples\"] == ms_best]\n",
    "        plt.figure()\n",
    "        plt.plot(xs, ys)\n",
    "        plt.title(f\"DBSCAN: silhouette vs eps (min_samples={ms_best})\")\n",
    "        plt.xlabel(\"eps\")\n",
    "        plt.ylabel(\"silhouette\")\n",
    "        plt.tight_layout()\n",
    "\n",
    "    return rows, best"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "f111102a",
   "metadata": {},
   "source": [
    "## Препроцессинг\n",
    "\n",
    "Для dataset 01–03 достаточно `StandardScaler`, так как признаки числовые и находятся в разных шкалах.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "239183f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T20:58:16.363434Z",
     "start_time": "2026-01-18T20:58:16.361919Z"
    }
   },
   "source": [
    "preprocess = Pipeline([\n",
    "    (\"scaler\", StandardScaler())\n",
    "])"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "38c166e7",
   "metadata": {},
   "source": [
    "## Запуск эксперимента на 3 датасетах\n",
    "\n",
    "Для каждого датасета:\n",
    "- EDA\n",
    "- KMeans (подбор k)\n",
    "- DBSCAN (подбор eps/min_samples)\n",
    "- Agglomerative (подбор k/linkage)\n",
    "- выбор лучшего решения (по silhouette как базовая эвристика)\n",
    "- PCA(2D) для лучшего решения\n",
    "- сохранение labels + графиков\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "c280093b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T20:58:16.369196Z",
     "start_time": "2026-01-18T20:58:16.367593Z"
    }
   },
   "source": [
    "DATASETS = {\n",
    "    \"ds1\": \"data/S07-hw-dataset-01.csv\",\n",
    "    \"ds2\": \"data/S07-hw-dataset-02.csv\",\n",
    "    \"ds3\": \"data/S07-hw-dataset-03.csv\",\n",
    "}\n",
    "\n",
    "metrics_summary = {}\n",
    "best_configs = {}"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "6b9a5fcf",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2026-01-18T20:58:16.381144Z"
    }
   },
   "source": [
    "for ds_key, path in DATASETS.items():\n",
    "    print(\"=\"*80)\n",
    "    print(ds_key, path)\n",
    "\n",
    "    df, sample_id, X = load_dataset(path)\n",
    "    basic_eda(df)\n",
    "\n",
    "    X_scaled = preprocess.fit_transform(X)\n",
    "\n",
    "    km_rows, km_best = search_kmeans(X_scaled, 2, 15)\n",
    "    fig_path = os.path.join(FIG_DIR, f\"{ds_key}_kmeans_silhouette_vs_k.png\")\n",
    "    plt.savefig(fig_path, dpi=160)\n",
    "    plt.show()\n",
    "\n",
    "    db_rows, db_best = search_dbscan(X_scaled)\n",
    "    if db_best is not None:\n",
    "        fig_path = os.path.join(FIG_DIR, f\"{ds_key}_dbscan_silhouette_vs_eps.png\")\n",
    "        plt.savefig(fig_path, dpi=160)\n",
    "        plt.show()\n",
    "\n",
    "    ag_rows, ag_best = search_agglomerative(X_scaled, 2, 15, linkages=(\"ward\", \"average\"))\n",
    "\n",
    "    candidates = [r for r in [km_best, db_best, ag_best] if r is not None]\n",
    "    best = max(candidates, key=lambda r: r[\"silhouette\"]) if candidates else None\n",
    "\n",
    "    if best is None:\n",
    "        print(\"Не удалось подобрать модель с >=2 кластерами для метрик\")\n",
    "        continue\n",
    "\n",
    "    if best[\"algo\"] == \"kmeans\":\n",
    "        model = KMeans(n_clusters=int(best[\"k\"]), random_state=RANDOM_STATE, n_init=10)\n",
    "        labels = model.fit_predict(X_scaled)\n",
    "    elif best[\"algo\"] == \"dbscan\":\n",
    "        model = DBSCAN(eps=float(best[\"eps\"]), min_samples=int(best[\"min_samples\"]))\n",
    "        labels = model.fit_predict(X_scaled)\n",
    "    else:\n",
    "        model = AgglomerativeClustering(n_clusters=int(best[\"k\"]), linkage=str(best[\"linkage\"]))\n",
    "        labels = model.fit_predict(X_scaled)\n",
    "\n",
    "    pca_path = os.path.join(FIG_DIR, f\"{ds_key}_best_pca.png\")\n",
    "    pca_scatter(X_scaled, labels, title=f\"{ds_key}: best={best['algo']}\", save_path=pca_path)\n",
    "\n",
    "    out_labels = pd.DataFrame({\"sample_id\": sample_id, \"cluster_label\": labels})\n",
    "    labels_path = os.path.join(LABELS_DIR, f\"labels_hw07_{ds_key}.csv\")\n",
    "    out_labels.to_csv(labels_path, index=False)\n",
    "\n",
    "    metrics_summary[ds_key] = {\n",
    "        \"kmeans_best\": km_best,\n",
    "        \"dbscan_best\": db_best,\n",
    "        \"agglomerative_best\": ag_best,\n",
    "        \"final_choice\": best,\n",
    "    }\n",
    "\n",
    "    best_configs[ds_key] = best\n",
    "\n",
    "    print(\"Best choice:\", best)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ds1 data/S07-hw-dataset-01.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   sample_id        f01        f02       f03         f04        f05  \\\n",
       "0          0  -0.536647 -69.812900 -0.002657   71.743147 -11.396498   \n",
       "1          1  15.230731  52.727216 -1.273634 -104.123302  11.589643   \n",
       "2          2  18.542693  77.317150 -1.321686 -111.946636  10.254346   \n",
       "3          3 -12.538905 -41.709458  0.146474   16.322124   1.391137   \n",
       "4          4  -6.903056  61.833444 -0.022466  -42.631335   3.107154   \n",
       "\n",
       "         f06        f07       f08  \n",
       "0 -12.291287  -6.836847 -0.504094  \n",
       "1  34.316967 -49.468873  0.390356  \n",
       "2  25.892951  44.595250  0.325893  \n",
       "3   2.014316 -39.930582  0.139297  \n",
       "4  -5.471054   7.001149  0.131213  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>f01</th>\n",
       "      <th>f02</th>\n",
       "      <th>f03</th>\n",
       "      <th>f04</th>\n",
       "      <th>f05</th>\n",
       "      <th>f06</th>\n",
       "      <th>f07</th>\n",
       "      <th>f08</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.536647</td>\n",
       "      <td>-69.812900</td>\n",
       "      <td>-0.002657</td>\n",
       "      <td>71.743147</td>\n",
       "      <td>-11.396498</td>\n",
       "      <td>-12.291287</td>\n",
       "      <td>-6.836847</td>\n",
       "      <td>-0.504094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15.230731</td>\n",
       "      <td>52.727216</td>\n",
       "      <td>-1.273634</td>\n",
       "      <td>-104.123302</td>\n",
       "      <td>11.589643</td>\n",
       "      <td>34.316967</td>\n",
       "      <td>-49.468873</td>\n",
       "      <td>0.390356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18.542693</td>\n",
       "      <td>77.317150</td>\n",
       "      <td>-1.321686</td>\n",
       "      <td>-111.946636</td>\n",
       "      <td>10.254346</td>\n",
       "      <td>25.892951</td>\n",
       "      <td>44.595250</td>\n",
       "      <td>0.325893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-12.538905</td>\n",
       "      <td>-41.709458</td>\n",
       "      <td>0.146474</td>\n",
       "      <td>16.322124</td>\n",
       "      <td>1.391137</td>\n",
       "      <td>2.014316</td>\n",
       "      <td>-39.930582</td>\n",
       "      <td>0.139297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-6.903056</td>\n",
       "      <td>61.833444</td>\n",
       "      <td>-0.022466</td>\n",
       "      <td>-42.631335</td>\n",
       "      <td>3.107154</td>\n",
       "      <td>-5.471054</td>\n",
       "      <td>7.001149</td>\n",
       "      <td>0.131213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12000 entries, 0 to 11999\n",
      "Data columns (total 9 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   sample_id  12000 non-null  int64  \n",
      " 1   f01        12000 non-null  float64\n",
      " 2   f02        12000 non-null  float64\n",
      " 3   f03        12000 non-null  float64\n",
      " 4   f04        12000 non-null  float64\n",
      " 5   f05        12000 non-null  float64\n",
      " 6   f06        12000 non-null  float64\n",
      " 7   f07        12000 non-null  float64\n",
      " 8   f08        12000 non-null  float64\n",
      "dtypes: float64(8), int64(1)\n",
      "memory usage: 843.9 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "         sample_id           f01           f02           f03           f04  \\\n",
       "count  12000.00000  12000.000000  12000.000000  12000.000000  12000.000000   \n",
       "mean    5999.50000     -2.424716     19.107804     -0.222063     -8.284501   \n",
       "std     3464.24595     11.014315     60.790338      0.500630     59.269838   \n",
       "min        0.00000    -19.912573    -92.892652     -1.590979   -134.303679   \n",
       "25%     2999.75000     -9.472623    -40.282955     -0.125145    -48.345007   \n",
       "50%     5999.50000     -6.869404     54.069335     -0.031753     16.211728   \n",
       "75%     8999.25000      0.523841     70.280739      0.054980     28.067178   \n",
       "max    11999.00000     24.403381    112.229523      0.512277     75.088604   \n",
       "\n",
       "                f05           f06           f07           f08  \n",
       "count  12000.000000  12000.000000  12000.000000  12000.000000  \n",
       "mean      -0.190717      0.962972      0.033724      0.007638  \n",
       "std        7.026435     14.794713     59.541782      0.607053  \n",
       "min      -11.869169    -20.521164   -215.098834     -2.633469  \n",
       "25%       -5.132473     -8.807706    -39.900520     -0.401483  \n",
       "50%        0.444730     -6.134169     -0.578494      0.005306  \n",
       "75%        3.942368      2.334426     39.719821      0.410132  \n",
       "max       13.717091     41.452857    213.381767      2.490745  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>f01</th>\n",
       "      <th>f02</th>\n",
       "      <th>f03</th>\n",
       "      <th>f04</th>\n",
       "      <th>f05</th>\n",
       "      <th>f06</th>\n",
       "      <th>f07</th>\n",
       "      <th>f08</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12000.00000</td>\n",
       "      <td>12000.000000</td>\n",
       "      <td>12000.000000</td>\n",
       "      <td>12000.000000</td>\n",
       "      <td>12000.000000</td>\n",
       "      <td>12000.000000</td>\n",
       "      <td>12000.000000</td>\n",
       "      <td>12000.000000</td>\n",
       "      <td>12000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5999.50000</td>\n",
       "      <td>-2.424716</td>\n",
       "      <td>19.107804</td>\n",
       "      <td>-0.222063</td>\n",
       "      <td>-8.284501</td>\n",
       "      <td>-0.190717</td>\n",
       "      <td>0.962972</td>\n",
       "      <td>0.033724</td>\n",
       "      <td>0.007638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3464.24595</td>\n",
       "      <td>11.014315</td>\n",
       "      <td>60.790338</td>\n",
       "      <td>0.500630</td>\n",
       "      <td>59.269838</td>\n",
       "      <td>7.026435</td>\n",
       "      <td>14.794713</td>\n",
       "      <td>59.541782</td>\n",
       "      <td>0.607053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>-19.912573</td>\n",
       "      <td>-92.892652</td>\n",
       "      <td>-1.590979</td>\n",
       "      <td>-134.303679</td>\n",
       "      <td>-11.869169</td>\n",
       "      <td>-20.521164</td>\n",
       "      <td>-215.098834</td>\n",
       "      <td>-2.633469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2999.75000</td>\n",
       "      <td>-9.472623</td>\n",
       "      <td>-40.282955</td>\n",
       "      <td>-0.125145</td>\n",
       "      <td>-48.345007</td>\n",
       "      <td>-5.132473</td>\n",
       "      <td>-8.807706</td>\n",
       "      <td>-39.900520</td>\n",
       "      <td>-0.401483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5999.50000</td>\n",
       "      <td>-6.869404</td>\n",
       "      <td>54.069335</td>\n",
       "      <td>-0.031753</td>\n",
       "      <td>16.211728</td>\n",
       "      <td>0.444730</td>\n",
       "      <td>-6.134169</td>\n",
       "      <td>-0.578494</td>\n",
       "      <td>0.005306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8999.25000</td>\n",
       "      <td>0.523841</td>\n",
       "      <td>70.280739</td>\n",
       "      <td>0.054980</td>\n",
       "      <td>28.067178</td>\n",
       "      <td>3.942368</td>\n",
       "      <td>2.334426</td>\n",
       "      <td>39.719821</td>\n",
       "      <td>0.410132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>11999.00000</td>\n",
       "      <td>24.403381</td>\n",
       "      <td>112.229523</td>\n",
       "      <td>0.512277</td>\n",
       "      <td>75.088604</td>\n",
       "      <td>13.717091</td>\n",
       "      <td>41.452857</td>\n",
       "      <td>213.381767</td>\n",
       "      <td>2.490745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "sample_id    0.0\n",
       "f01          0.0\n",
       "f02          0.0\n",
       "f03          0.0\n",
       "f04          0.0\n",
       "f05          0.0\n",
       "f06          0.0\n",
       "f07          0.0\n",
       "f08          0.0\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9e77e0b7",
   "metadata": {},
   "source": [
    "## Устойчивость (только для одного датасета)\n",
    "\n",
    "Проверка устойчивости для KMeans на `ds2`: 5 запусков с разными `random_state`, затем считаем средний ARI между разбиениями.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee0ba19",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = DATASETS[\"ds2\"]\n",
    "df, sample_id, X = load_dataset(path)\n",
    "X_scaled = preprocess.fit_transform(X)\n",
    "\n",
    "k = metrics_summary.get(\"ds2\", {}).get(\"kmeans_best\", {}).get(\"k\")\n",
    "if k is None:\n",
    "    k = 3\n",
    "\n",
    "labels_list = []\n",
    "seeds = [1, 2, 3, 4, 5]\n",
    "for seed in seeds:\n",
    "    km = KMeans(n_clusters=int(k), random_state=seed, n_init=10)\n",
    "    labels_list.append(km.fit_predict(X_scaled))\n",
    "\n",
    "aris = []\n",
    "for i in range(len(labels_list)):\n",
    "    for j in range(i+1, len(labels_list)):\n",
    "        aris.append(adjusted_rand_score(labels_list[i], labels_list[j]))\n",
    "\n",
    "print(f\"Stability for ds2 (KMeans k={k})\")\n",
    "print(\"pairwise ARI:\", [round(a, 4) for a in aris])\n",
    "print(\"mean ARI:\", float(np.mean(aris)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88c897a",
   "metadata": {},
   "source": [
    "## Сохранение артефактов (JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cb5873",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(ARTIFACTS_DIR, \"metrics_summary.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(metrics_summary, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "with open(os.path.join(ARTIFACTS_DIR, \"best_configs.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(best_configs, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\"-\", os.path.join(ARTIFACTS_DIR, \"metrics_summary.json\"))\n",
    "print(\"-\", os.path.join(ARTIFACTS_DIR, \"best_configs.json\"))\n",
    "print(\"- labels in\", LABELS_DIR)\n",
    "print(\"- figures in\", FIG_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
