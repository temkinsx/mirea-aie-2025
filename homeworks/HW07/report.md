# HW07 – Report

## 1. Datasets

Работал с тремя из четырёх синтетических наборов: `S07-hw-dataset-01`, `S07-hw-dataset-02`, `S07-hw-dataset-03`.

### 1.1 Dataset A

- Файл: `S07-hw-dataset-01.csv`
- Размер: 12 000 строк × 9 столбцов (8 признаков + `sample_id`)
- Признаки: только числовые (`f01`–`f08`)
- Пропуски: отсутствуют
- Подлости: шкалы различаются на 2–3 порядка (`f03` около 1, `f02/f07` достигают ±200), есть шумовые поля (`f05`, `f08`) и коррелированные признаки, поэтому без масштабирования метрики резко падают.

### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`
- Размер: 8 000 × 4 (3 признака + `sample_id`)
- Признаки: числовые (`x1`, `x2`, `z_noise`)
- Пропуски: нет
- Подлости: кластеры нелинейные (дуги в пространстве `x1/x2`), заметные выбросы и шумовой признак `z_noise`, из-за чего KMeans часто сливает классы, а DBSCAN чувствителен к `eps`.

### 1.3 Dataset C

- Файл: `S07-hw-dataset-03.csv`
- Размер: 15 000 × 5 (4 признака + `sample_id`)
- Признаки: числовые (`x1`, `x2`, `f_corr`, `f_noise`)
- Пропуски: нет
- Подлости: разные плотности и протяжённости кластеров, сильный шум `f_noise`, частичное перекрытие в проекции `x1/x2`, поэтому методам с предположением о сферичности тяжело.

## 2. Protocol

1. Для каждого CSV — загрузка, отдельное хранение `sample_id`, EDA (head/info/describe, оценка пропусков и распределений).
2. Препроцессинг строится функцией `build_preprocessor`: числовые признаки → `SimpleImputer(strategy='median')` + `StandardScaler`; категориальные (их в текущих данных нет, но код готов) → `SimpleImputer(strategy='most_frequent')` + `OneHotEncoder(handle_unknown='ignore')`. Такой конвейер устойчив к пропускам и разным шкалам.
3. Поиск гиперпараметров:
   - `KMeans`: `k ∈ [2, 15]`, `random_state=42`, `n_init=10`.
   - `DBSCAN`: `eps ∈ [0.2, 2.0]` (19 точек сетки), `min_samples ∈ {5, 10}`.
   - `AgglomerativeClustering`: `k ∈ [2, 15]`, `linkage ∈ {ward, average}`.
   Лучшие модели выбирались по максимальному silhouette среди валидных конфигураций.
4. Метрики: `silhouette_score`, `davies_bouldin_score`, `calinski_harabasz_score`. Для DBSCAN метрики считались без шумовых точек, дополнительно фиксировалась доля шума.
5. Визуализация: PCA(2D) для победившей модели каждого датасета и графики подбора (`silhouette vs k/eps`). Все рисунки сохранены в `artifacts/figures/`.
6. Артефакты: `metrics_summary.json`, `best_configs.json`, CSV с метками (`artifacts/labels/labels_hw07_ds*.csv`). Для `ds2` дополнительно проверена устойчивость: 5 запусков KMeans с разными seed.

## 3. Models

На каждом датасете сравнивались:

- `KMeans` с подбором `k` в диапазоне 2–15 (фиксированы `random_state=42`, `n_init=10`).
- `DBSCAN` с сеткой `eps` (0.2–2.0) и `min_samples` (5, 10), учётом доли шума.
-, `AgglomerativeClustering` с `k=2..15` и `linkage ∈ {ward, average}`.

Эти три семейства покрывают разные гипотезы о форме/плотности кластеров.

## 4. Results

### 4.1 Dataset A

- Лучший метод: `KMeans`, `k=2`.
- Метрики: silhouette 0.522, Davies–Bouldin 0.685, Calinski–Harabasz 11 786.95.
- DBSCAN и Agglomerative дали те же разбиения (для DBSCAN доля шума 0), поэтому выбрал KMeans как наиболее понятный через центры.
- Решение выглядит разумным: кластеры почти сферичны после стандартизации, отличие идёт по крупным признакам `f02/f07`, что видно на PCA.

### 4.2 Dataset B

- Лучший метод: `AgglomerativeClustering` (average linkage), `k=2`.
- Метрики: silhouette 0.420, Davies–Bouldin 0.879, Calinski–Harabasz 395.48.
- Лучший DBSCAN (`eps=0.8`, `min_samples=10`) имел silhouette 0.414 и отмечал ≈1.2 % шума, но агломеративное решение стабильнее и не теряет точки.
- Иерархический метод лучше справился с дугообразной структурой и несколькими выбросами, что подтверждается PCA-визуализацией.

### 4.3 Dataset C

- Лучший метод: `AgglomerativeClustering` (average linkage), `k=2`.
- Метрики: silhouette 0.425, Davies–Bouldin 0.814, Calinski–Harabasz 8.94.
- `DBSCAN` страдал от неоднородной плотности (silhouette 0.142, шум ≈3.2 %), `KMeans (k=3)` показывал лишь 0.316.
- Agglomerative аккуратно отделяет плотный «ядро»-кластер от разреженного хвоста с большими `x1/x2`.

## 5. Analysis

### 5.1 Сравнение алгоритмов

- KMeans блестяще работает на `ds1`, где после стандартизации кластеры действительно похожи на гиперсферы, но ломается на `ds2/ds3` из-за изогнутых структур и неодинаковой плотности.
- DBSCAN полезен, когда есть плотные регионы и шум (частично `ds2`), но сильно зависит от `eps`: малое значение даёт много шума, большое — сливает всё в один кластер.
- Agglomerative оказался самым универсальным: за счёт выбора `linkage` он справляется и с вытянутыми, и с плотными структурами, главное — корректное масштабирование признаков.

### 5.2 Устойчивость

- Проверка: 5 запусков `KMeans(k=2)` на `ds2` с seed {1,2,3,4,5}.
- Попарные ARI лежат в диапазоне [0.9990; 1.0], среднее ARI = 0.9995.
- Вывод: после стандартизации решение практически инвариантно к случайной инициализации — модель устойчива.

### 5.3 Интерпретация кластеров

- `ds1`: один кластер концентрирует экстремальные значения `f02/f07` (выбросы) и отрицательные `f01`, второй содержит умеренные значения и около нуля шумовые признаки (`f05/f08`).
- `ds2`: агломеративный алгоритм выделил компактный центр (`x1≈0.5`, `x2≈0.2`) и вытянутую дугу с отрицательным `x1` и высоким `x2`; шумовое поле почти не влияет на разбиение.
- `ds3`: два режима — плотный «ядро» около (`x1≈1`, `x2≈1`) и разреженный хвост с большими `x1`, положительным `f_corr` и всплесками `f_noise`.

## 6. Conclusion

1. Масштабирование и импутация стоит выполнять даже при отсутствии явных пропусков — так конвейер готов к более «грязным» данным.
2. Набор внутренних метрик (silhouette + DB + CH) помогает отбрасывать вырожденные решения и сравнивать алгоритмы честно.
3. Разные допущения о форме/плотности требуют разных моделей, поэтому минимум один density-based и один иерархический алгоритм обязателен.
4. Сохранение артефактов (метрик, меток, графиков) делает эксперимент воспроизводимым и упрощает отчёт.
5. Проверка устойчивости выявляет, насколько опасна случайная инициализация и можно ли доверять результату в проде.
