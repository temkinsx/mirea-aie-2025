# Домашнее задание к семинару 07 (HW07)

Тема: кластеризация, внутренние метрики качества, PCA/t-SNE и "честный" unsupervised-эксперимент на синтетических данных.

HW07 относится к семинару **S07** и выполняется в личном репозитории студента (на основе шаблона курса) в папке `homeworks/HW07/`.

---

## 1. Цель

Закрепить:

- понимание различий между семействами методов кластеризации:
  - **KMeans** (геометрия "шаров" и выбор `k`),
  - **DBSCAN** (плотность, шум, выбросы, нелинейные формы),
  - **Agglomerative** (иерархическая логика и влияние `linkage`);
- навыки корректного **препроцессинга** для distance-based методов:
  - масштабирование,
  - обработка пропусков,
  - (при необходимости) кодирование категориальных признаков;
- оценку качества кластеризации **без истинных меток**:
  - `silhouette_score` (выше – лучше),
  - `davies_bouldin_score` (ниже – лучше),
  - `calinski_harabasz_score` (выше – лучше);
- аккуратную **визуализацию** результатов:
  - PCA(2D) обязательно,
  - t-SNE (опционально, с правильными оговорками);
- оформление результата в виде ноутбука + короткого отчёта + артефактов (как в предыдущих ДЗ).

---

## 2. Задание

### 2.1. Структура для HW07 (обязательно)

1) В корне репозитория должна быть папка `homeworks/` (создать, если её ещё нет).  
2) Внутри `homeworks/` создать папку `HW07/`.  
3) В папке `homeworks/HW07/` создать:

- основной ноутбук: `HW07.ipynb`
- отчёт: `report.md`
- папку с данными: `data/`
- папку для артефактов: `artifacts/`
  - рекомендуется внутри `artifacts/` завести подпапку `figures/` для графиков

> Имена папок и файлов должны быть **строго такими**, как указано (регистр важен).

---

### 2.2. Учебные датасеты S07 (выбрать 3 из 4)

Для HW07 предоставлены **4 синтетических CSV-файла**. Нужно выбрать **любые 3** (четвёртый – опционально).

Положите выбранные CSV в `homeworks/HW07/data/`.

Файлы:

- `S07-hw-dataset-01.csv`  
  Числовые признаки в разных шкалах + шумовые признаки. Без масштабирования результаты обычно "едут".

- `S07-hw-dataset-02.csv`  
  Нелинейная структура + выбросы + лишний шумовой признак. Хорошо демонстрирует, где KMeans проигрывает.

- `S07-hw-dataset-03.csv`  
  Кластеры разной плотности + фоновый шум. Часто провоцирует ошибки выбора `eps` для DBSCAN.

- `S07-hw-dataset-04.csv`  
  Высокая размерность + 2 категориальных признака + пропуски в числовых. Требует аккуратного препроцессинга.

Во всех CSV:

- есть колонка `sample_id` (это **не** признак, используйте только как идентификатор);
- истинных меток кластеров **нет**.

Требование к путям: в ноутбуке используйте **относительные пути** (без абсолютных путей к домашним каталогам).

---

### 2.3. Содержание ноутбука `HW07.ipynb` (основная часть)

В ноутбуке `homeworks/HW07/HW07.ipynb` необходимо выполнить следующие шаги.

#### 2.3.1. Загрузка данных и первичный анализ (для каждого датасета)

Для **каждого** из 3 выбранных CSV:

1) Загрузить CSV в `pandas.DataFrame`.  
2) Зафиксировать минимум:
   - `head()`, `info()`, базовые статистики (`describe()` или аналог);
   - проверка пропусков (кол-во/доли);
   - типы признаков (числовые / категориальные).  
3) Определить:
   - `X` – признаки (все столбцы, кроме `sample_id`);
   - `sample_id` хранить отдельно (для сохранения результатов).

#### 2.3.2. Препроцессинг (обязательно)

Для каждого датасета оформите препроцессинг **явно** и применяйте его одинаково ко всем моделям данного датасета.

Минимум:

- масштабирование числовых признаков: `StandardScaler`;
- если есть пропуски – обработать (`SimpleImputer`);
- если есть категориальные признаки (dataset-04) – один из вариантов:
  - закодировать (`OneHotEncoder(handle_unknown="ignore")`), **или**
  - осознанно исключить категориальные признаки и объяснить почему (в отчёте).

Рекомендация: использовать `Pipeline`/`ColumnTransformer` (не обязательно идеально, но логика должна быть понятной).

#### 2.3.3. Модели недели 7 (для каждого датасета – минимум 2 алгоритма)

Для **каждого датасета** сравните минимум **2** алгоритма:

1) **KMeans** (обязательно):
   - подобрать `k` в разумном диапазоне (например, 2…20);
   - фиксировать `random_state` и `n_init`;
   - показать хотя бы один график "метрика vs k" (например, silhouette vs k).

2) **Один алгоритм на выбор** (обязательно):
   - `DBSCAN` (подбор `eps` и `min_samples`), **или**
   - `AgglomerativeClustering` (подбор `k` + выбор `linkage`, хотя бы 2 варианта).

> Можно делать 3-й алгоритм (приветствуется), но он не обязателен.

#### 2.3.4. Метрики качества (обязательно)

Для каждого датасета и каждого сравниваемого алгоритма посчитать:

- `silhouette_score`
- `davies_bouldin_score`
- `calinski_harabasz_score`

Важно для DBSCAN:

- учесть шум (`label = -1`):
  - явно вывести долю шума,
  - метрики считать либо на non-noise точках (и это указать), либо честно объяснить иной выбор.

#### 2.3.5. Визуализация (обязательно)

Для каждого датасета:

- PCA(2D) scatter с раскраской по полученным кластерам (для **лучшего** решения по датасету);
- минимум один дополнительный график по ходу подбора параметров (например, silhouette vs k или silhouette vs eps).

t-SNE – опционально:

- если делаете, фиксируйте `random_state` и коротко поясните, как правильно интерпретировать t-SNE (это визуализация локальной структуры, а не "доказательство качества").

#### 2.3.6. Устойчивость (обязательно, но только для одного датасета)

Выберите **один** из ваших датасетов и проведите мини-проверку устойчивости:

- для KMeans: 5 запусков с разными `random_state` (или 5 разными подвыборками) и оценка похожести разбиений (например, ARI между результатами), **или**
- любая другая аккуратная проверка устойчивости (кратко описать и обосновать).

#### 2.3.7. Итог по каждому датасету (обязательно)

Для каждого датасета в конце блока:

- выбрать "лучший" метод/настройку (не обязательно тот, где максимум silhouette – главное, чтобы выбор был объяснён);
- написать 5-10 строк: что получилось, где были сложности (шкалы/выбросы/плотность/пропуски), почему выбранный метод уместен.

---

### 2.4. Артефакты эксперимента (обязательно)

В папке `homeworks/HW07/artifacts/` должны быть:

- `metrics_summary.json` – сводка метрик по датасетам и моделям (silhouette/DB/CH + доля шума для DBSCAN);
- `best_configs.json` – какие параметры выбраны как "лучшие" для каждого датасета (и каким критерием);
- `labels/` – CSV-файлы с присвоенными кластерами для **лучшего** решения на каждом датасете, например:
  - `labels_ hw07_ds1.csv`, `labels_hw07_ds2.csv`, ...
  Формат: `sample_id,cluster_label` (для DBSCAN кластер `-1` допустим);
- `figures/` – минимум 6 изображений:
  - по 1 PCA(2D) scatter на каждый из 3 датасетов (итого минимум 3),
  - и ещё минимум 3 графика "подбор параметров / метрики" (например, silhouette vs k/eps, сравнение linkage и т.п.).

> Формат артефактов (json/csv/png) можно выбирать свободно, главное – чтобы их можно было открыть и понять без запуска ноутбука.

---

### 2.5. Отчёт `report.md` (обязательно)

1) В материалах семинара будет шаблон: `S07-hw-report-template.md`.  
2) Нужно создать файл `homeworks/HW07/report.md` и заполнить его **по шаблону**.

Важно:

- не меняйте названия разделов (заголовков) в отчёте;
- вставляйте результаты и выводы в соответствующие секции.

---

## 3. Требования к структуре и именованию (итог)

К дедлайну в репозитории должно быть:

- `homeworks/HW07/HW07.ipynb`
- `homeworks/HW07/report.md`
- `homeworks/HW07/data/` (3 выбранных CSV)
- `homeworks/HW07/artifacts/` (см. состав выше)

Требования:

- названия папок и файлов - строго как указано;
- путь к CSV - относительный;
- ноутбук выполняется **без ошибок** при последовательном запуске всех ячеек;
- результаты эксперимента оформлены: метрики, сравнение алгоритмов, визуализации, выводы.

---

## 4. Критерии зачёта

HW07 считается зачтённым, если:

1) Соблюдена структура `homeworks/HW07/` и нейминг файлов.

2) В `HW07.ipynb` есть (для **каждого** из 3 датасетов):

   - загрузка выбранного CSV;
   - базовый EDA (тип/пропуски/описание признаков);
   - явный препроцессинг (scaling обязательно; пропуски/категориальные – если есть);
   - сравнение минимум 2 алгоритмов (KMeans + (DBSCAN или Agglomerative));
   - расчёт внутренних метрик (silhouette/DB/CH) и их интерпретация;
   - PCA(2D) визуализация для лучшего решения;
   - текстовый вывод по датасету.

3) Есть проверка устойчивости (хотя бы на одном датасете).

4) В `artifacts/` лежат требуемые файлы и минимум 6 графиков в `figures/`.

5) Заполнен `report.md` по шаблону.

---

## 5. Опциональная часть (для желающих)

Не обязательна для зачёта, но приветствуется:

- t-SNE для 1-2 датасетов (с фиксированным `random_state` и аккуратной интерпретацией);
- сравнение времени выполнения (fit/predict) разных подходов на больших датасетах;
- более аккуратный подбор параметров DBSCAN (например, k-distance plot как эвристика);
- сравнение результатов при разных вариантах препроцессинга (например, с PCA и без).

---

## 6. Сроки и порядок сдачи

- Работа выполняется **индивидуально**.
- Дедлайн объявляется преподавателем отдельно.
- Факт сдачи: к дедлайну в репозитории есть `homeworks/HW07/` со всеми файлами и корректно выполненным ноутбуком.
